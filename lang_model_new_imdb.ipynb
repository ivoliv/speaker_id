{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ONE/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "# To create python file:\n",
    "# jupyter nbconvert --to=python lang_model_new.ipynb\n",
    "\n",
    "import utils.data_import as data_import\n",
    "import utils.imdb_data as imdb_data\n",
    "import utils.ml_utils as ml_utils\n",
    "import model.neural as neural\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data, vocab\n",
    "\n",
    "import os, sys\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "#from tqdm import tnrange, tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import importlib\n",
    "\n",
    "import settings\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in notebook: True\n"
     ]
    }
   ],
   "source": [
    "in_notebook = ml_utils.in_ipynb()\n",
    "print('Running in notebook:', in_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cuda.\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    print('Cuda is available!')\n",
    "    print('Device:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print('No cuda.')\n",
    "\n",
    "if in_notebook:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing vocab from vocab.p... Done.\n",
      "Imported vocab:  10,954\n",
      "Read total of: 1,000 lines from imdb file.\n",
      "Number of classes: 2: {'negative': 0, 'positive': 1}\n",
      "Generated train: 700 lines\n",
      "Generated valid: 150 lines\n",
      "Generated test:  150 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ONE/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/anaconda3/envs/ONE/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>[1249, 9389, 38, 1384, 38, 2, 5207, 119, 18, 2...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "      <td>[456, 1871, 23, 2158, 7264, 3995, 10618, 185, ...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0</td>\n",
       "      <td>[247, 130, 158, 216, 154, 598, 44, 456, 57, 16...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>[140, 241, 2819, 18, 3922, 18, 60, 5290, 2, 44...</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0</td>\n",
       "      <td>[2, 2, 300, 10611, 5830, 24, 2, 105, 21, 387, ...</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                             review  len\n",
       "498          0  [1249, 9389, 38, 1384, 38, 2, 5207, 119, 18, 2...  206\n",
       "243          0  [456, 1871, 23, 2158, 7264, 3995, 10618, 185, ...  185\n",
       "314          0  [247, 130, 158, 216, 154, 598, 44, 456, 57, 16...  142\n",
       "202          0  [140, 241, 2819, 18, 3922, 18, 60, 5290, 2, 44...  114\n",
       "300          0  [2, 2, 300, 10611, 5830, 24, 2, 105, 21, 387, ...  889"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = imdb_data.ImdbCorpus(filename=settings.imdb_file, lines=settings.lines_imbd, vocab_file='vocab.p')\n",
    "corpus.train.itoklist_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if in_notebook:\n",
    "    print(corpus.vocab.most_frequent(to=20))\n",
    "    print(corpus.classes.most_frequent())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if in_notebook:\n",
    "    corpus.train.show_stoklist(corpus.vocab, 2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "corpus.train.itoklist_df = utils.shuffle(corpus.train.itoklist_df)\n",
    "corpus.batchify(batch_size=settings.batch_size_imdb, seq_length=settings.window_size_imbd)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "corpus.train.itoklist_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "seqlengths = np.array(corpus.train.batch_start_end) \n",
    "seqlengths = seqlengths[:,1] - seqlengths[:,0] - 1\n",
    "display(seqlengths)\n",
    "rand_range=5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if in_notebook:\n",
    "    corpus.train.show_itoklist(3)\n",
    "    corpus.train.show_stoklist(corpus.vocab, 3)\n",
    "    print(corpus.train.batch_matrix[corpus.train.batch_start_end[0][0]:corpus.train.batch_start_end[0][1],2])\n",
    "    #df = corpus.train.batch_stats()\n",
    "    #df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of batches: 23\n",
      " Preserved texts: 690\n",
      " Matrix size:       torch.Size([3627, 30])\n",
      " Number of batches: 5\n",
      " Preserved texts: 150\n",
      " Matrix size:       torch.Size([846, 30])\n",
      " Number of batches: 5\n",
      " Preserved texts: 150\n",
      " Matrix size:       torch.Size([834, 30])\n"
     ]
    }
   ],
   "source": [
    "train_dl = imdb_data.ImdbTextDataset(corpus.train, pad_idx=corpus.vocab.stoi['<pad>'],\n",
    "                                     batch_size=settings.batch_size_imdb, seq_length=settings.window_size_imbd, \n",
    "                                     rand_range=5, sort=True, rebatch_and_shuffle=True)\n",
    "valid_dl = imdb_data.ImdbTextDataset(corpus.valid, pad_idx=corpus.vocab.stoi['<pad>'],\n",
    "                                     batch_size=settings.batch_size_imdb, seq_length=settings.window_size_imbd, \n",
    "                                     rand_range=5, sort=True)\n",
    "test_dl = imdb_data.ImdbTextDataset(corpus.test, pad_idx=corpus.vocab.stoi['<pad>'],\n",
    "                                    batch_size=settings.batch_size_imdb, seq_length=settings.window_size_imbd, \n",
    "                                    rand_range=5, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6399,  1249,  1249,  ...,   247,   158,  1249],\n",
      "        [  962,   552,   589,  ...,   130,  4296,   552],\n",
      "        [   47, 10055,    23,  ...,   158,    18,   503],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,  8416,     2,    97],\n",
      "        [    0,     0,     0,  ...,    16,     2,    16],\n",
      "        [    0,     0,     0,  ...,     1,     1,     1]])\n",
      "tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1])\n",
      "[[649, 792], [941, 1096], [513, 649], [3083, 3268], [0, 61], [2535, 2721], [3446, 3627], [149, 264], [2907, 3083], [1435, 1612], [792, 941], [264, 385], [2163, 2349], [385, 513], [2721, 2907], [3268, 3446], [1263, 1435], [2349, 2535], [1612, 1795], [1795, 1979], [1979, 2163], [61, 149], [1096, 1263]]\n"
     ]
    }
   ],
   "source": [
    "if in_notebook:\n",
    "    train_x, train_y = next(iter(train_dl))\n",
    "    print(train_x)\n",
    "    print(train_y)\n",
    "    print(train_dl.itoklistFrame.batch_start_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 142\n",
      "i just watched <unk> <unk> return to <unk> <unk> streets of <unk> and dead <unk> walk . all excellent . this sorry <unk> of <unk> is <unk> done and poorly acted <unk> in the previous <unk> captain call and <unk> <unk> come off as <unk> <unk> <unk> . despite the fact that <unk> call is played by a different actor every time each one quickly won me over . in dead <unk> walk the boys are <unk> as the younger versions of the experienced texas <unk> . in <unk> moon they are just a couple of <unk> <unk> . i had to stop watching <unk> i <unk> many of the <unk> reviews for this show were written by the people who made this <unk> pile . <unk> a sorry end to an otherwise great franchise . <eol> <pad> <pad> <pad> <pad> <pad> ## negative ##\n",
      "1 154\n",
      "i have to <unk> seventeen & missing is much better than i expected . the perception i took from the <unk> was that it would be just <unk> but i was <unk> surprised with this impressive mystery <unk> <unk> <unk> is <unk> a <unk> who <unk> her <unk> <unk> <unk> <unk> not attend a <unk> graduation party one <unk> but <unk> <unk> her <unk> wishes and takes off for the party <unk> . when <unk> does not come <unk> <unk> <unk> something is <unk> and she begins to have visions of her daughter and the events that led to her <unk> <unk> seventeen & missing is better than so many other tv movies of this <unk> as it is not so predictable . <unk> is the reason to see this <unk> and most of it comes off as <unk> . this <unk> original movie <unk> last night . <unk> <eol> <pad> <pad> <pad> <pad> ## positive ##\n"
     ]
    }
   ],
   "source": [
    "if in_notebook:\n",
    "    for idx, (x, y) in enumerate(train_dl):\n",
    "        if idx >= 2:\n",
    "            break\n",
    "        print(idx, len(x[:,1]))\n",
    "        for i in x[:,1]:\n",
    "            print(corpus.vocab.itos[i], end=' ')\n",
    "        print('##', corpus.classes.itos[y[1].item()], '##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neural.class_model_LSTM(vocab_dim=len(corpus.vocab),\n",
    "                                emb_dim=settings.emb_dim,\n",
    "                                hidden_dim=settings.hidden_dim,\n",
    "                                n_layers=settings.num_layers,\n",
    "                                dropout=settings.dropout,\n",
    "                                n_classes=corpus.n_classes\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_model_LSTM(\n",
      "  (embedding): Embedding(10954, 50)\n",
      "  (lstm): LSTM(50, 300, num_layers=2, dropout=0.4, bidirectional=True)\n",
      "  (fc): Linear(in_features=600, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.4)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if in_notebook:\n",
    "    x, y = train\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    preds = model(x.cuda())\n",
    "    print(preds.shape)\n",
    "    print(y)\n",
    "    print(preds)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    loss = loss_func(preds, y.cuda().long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_weights_imdb_300.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclass = []\n",
    "missclass_next = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epochs(model, train_dl, valid_dl, epochs=settings.epochs,\n",
    "               losses=[], missclass=[]):\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "    #opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    #loss_func = nn.NLLLoss()\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.8)\n",
    "    \n",
    "    best_missclass_te = 1e10\n",
    "    \n",
    "    try: # Allow for user interrupt\n",
    " \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            \n",
    "            scheduler.step()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            model.train() # turn on training mode\n",
    "\n",
    "            num_vals = 0\n",
    "            num_correct = 0\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            for x, y in tqdm(train_dl, desc='Train {}/{}'.format(epoch, epochs)):\n",
    "                opt.zero_grad()\n",
    "                \n",
    "                if cuda:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "\n",
    "                preds = model(x)\n",
    "                loss = loss_func(preds, y.long())\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "                opt.step()\n",
    "\n",
    "                running_loss += loss.item() * x.size(0) / x.size(1)\n",
    "\n",
    "                _, y_preds = torch.max(preds, dim=1)\n",
    "                num_correct += torch.sum(y == y_preds).item()\n",
    "                num_vals += y.size(0)\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            missclass_tr = 1 - num_correct / num_vals\n",
    "\n",
    "            epoch_loss = running_loss / len(train_dl)\n",
    "\n",
    "            num_vals = 0\n",
    "            num_correct = 0\n",
    "\n",
    "            # calculate the validation loss for this epoch\n",
    "            val_loss = 0.0\n",
    "            model.eval() # turn on evaluation mode\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for x, y in tqdm(valid_dl, desc='Valid {}/{}'.format(epoch, epochs)):\n",
    "                    if cuda:\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()   \n",
    "                        \n",
    "                    preds = model(x)\n",
    "                    loss = loss_func(preds, y.long())\n",
    "\n",
    "                    val_loss += loss.item() * x.size(0) / x.size(1)\n",
    "\n",
    "                    _, y_preds = torch.max(preds, dim=1)\n",
    "                    num_correct += torch.sum(y == y_preds).item()\n",
    "                    num_vals += y.size(0)\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            missclass_te = 1 - num_correct / num_vals\n",
    "            val_loss /= len(valid_dl)\n",
    "            \n",
    "            missclass.append((missclass_tr, missclass_te))\n",
    "            losses.append((epoch_loss, val_loss))\n",
    "\n",
    "            print('Epoch: {}/{}, Loss: [{:.4f}, {:.4f}], Miss: [{:.2%}, {:.2%}]'\\\n",
    "                  .format(epoch, epochs, epoch_loss, val_loss, \n",
    "                          missclass_tr, missclass_te))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            if missclass_te < best_missclass_te:\n",
    "                print('Improved validation. Saving weights file...', end=' ', flush=True)\n",
    "                torch.save(model, 'model_weights_imdb_300.pt')\n",
    "                print('Done.', flush=True)\n",
    "                best_missclass_te = missclass_te\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print('Stopping with latest weights.')\n",
    "        \n",
    "    return model, opt, losses, missclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1/10:  13%|█▎        | 3/23 [00:09<01:03,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping with latest weights.\n"
     ]
    }
   ],
   "source": [
    "model, opt, losses, missclass = run_epochs(model, train_dl, valid_dl, epochs=settings.epochs,\n",
    "                                           losses=losses, missclass=missclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0802, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(valid_dl))\n",
    "if cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "preds = model(x)\n",
    "_, y_preds = torch.max(preds, dim=1)\n",
    "loss = loss_func(preds, y.long())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1])\n",
      "tensor([[-1.3594,  1.9757],\n",
      "        [-5.8589,  4.5518],\n",
      "        [-3.6115,  3.6212],\n",
      "        [ 2.4391, -3.5015],\n",
      "        [-2.7058,  1.4551],\n",
      "        [-3.7280,  3.4330],\n",
      "        [ 5.3058, -4.5454],\n",
      "        [-3.4714,  2.6797],\n",
      "        [ 3.7521, -5.2298],\n",
      "        [ 1.9088, -2.1255],\n",
      "        [ 4.0376, -4.4046],\n",
      "        [ 4.3677, -4.9762],\n",
      "        [ 2.5214, -2.4705],\n",
      "        [-3.6107,  2.5149],\n",
      "        [-0.9628,  0.0898],\n",
      "        [-3.4392,  2.7303],\n",
      "        [-5.0814,  3.8719],\n",
      "        [-3.3890,  2.0190],\n",
      "        [-1.7097,  0.3362],\n",
      "        [-2.1474,  1.6244],\n",
      "        [ 4.2879, -4.3036],\n",
      "        [-2.1844,  1.3727],\n",
      "        [ 3.9586, -4.3256],\n",
      "        [-5.4731,  3.9186],\n",
      "        [ 2.3052, -1.7960],\n",
      "        [ 2.5956, -2.7325],\n",
      "        [-4.0342,  2.9954],\n",
      "        [-2.3212,  2.2222],\n",
      "        [-3.1035,  1.8777],\n",
      "        [-4.7055,  3.6266]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(y_preds[:])\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if in_notebook:\n",
    "    plt.plot(losses)\n",
    "    plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if in_notebook:\n",
    "    plt.plot(missclass)\n",
    "    plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
