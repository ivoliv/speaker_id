{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ONE/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n",
      "/anaconda3/envs/ONE/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import utils.data_import as data_import\n",
    "import utils.ml_utils as ml_utils\n",
    "\n",
    "import torch, torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data, vocab\n",
    "\n",
    "import os, sys\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "#from tqdm import tnrange, tqdm_notebook\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cuda.\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    print('Cuda is available!')\n",
    "    print('Device:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print('No cuda.')\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text length:  2,051,910 token sequence.\n",
      "Generated text length: 274,835 tokens.\n",
      "Writing files to ./data\n",
      "Train and validation files written to disk.\n",
      "Sizes: (340, 3) (60, 3)\n"
     ]
    }
   ],
   "source": [
    "import settings\n",
    "\n",
    "if settings.ORIG_DATA == 0:\n",
    "    train_file = 'training.txt'\n",
    "    train, valid = data_import.normalize_and_split(org_data_path, train_file, test_size=settings.test_size)\n",
    "elif settings.ORIG_DATA == 1:\n",
    "    train_file = settings.imdb_file\n",
    "    train, valid = data_import.import_imbd(train_file, to=10000, test_size=settings.test_size)\n",
    "elif settings.ORIG_DATA == 2:\n",
    "    df = data_import.import_wikitext(settings.batch_size, window_size=settings.window_size, \n",
    "                                     lines=settings.lines, prob_cut=0.05, cut_factor=0.50)\n",
    "    train, valid = data_import.create_splits(df, test_size=settings.test_size)\n",
    "    \n",
    "data_import.create_split_files('.', train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Valkyria Chronicles III = Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third\n",
      "Valkyria Chronicles III = Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    340.000000\n",
       "mean      67.352941\n",
       "std        2.810456\n",
       "min       61.000000\n",
       "25%       65.000000\n",
       "50%       66.000000\n",
       "75%       69.000000\n",
       "max       71.000000\n",
       "Name: statement, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "statement_lengths = train_df['statement'].apply(lambda x: len(x.split()))\n",
    "print(train_df['statement'][0])\n",
    "print(train_df['tag'][0])\n",
    "display(statement_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>statement</th>\n",
       "      <th>tag_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Her father , who was a musician in Sri Lanka ,...</td>\n",
       "      <td>. Her father , who was a musician in Sri Lanka...</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>of fourteen . After receiving her early educat...</td>\n",
       "      <td>age of fourteen . After receiving her early ed...</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>she had aspired to become an actress at a youn...</td>\n",
       "      <td>, she had aspired to become an actress at a yo...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>crowned the winner of the Miss Universe Sri La...</td>\n",
       "      <td>was crowned the winner of the Miss Universe Sr...</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>confidence \" . In 2006 , she appeared in a mus...</td>\n",
       "      <td>, confidence \" . In 2006 , she appeared in a m...</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tag  \\\n",
       "340  Her father , who was a musician in Sri Lanka ,...   \n",
       "341  of fourteen . After receiving her early educat...   \n",
       "342  she had aspired to become an actress at a youn...   \n",
       "343  crowned the winner of the Miss Universe Sri La...   \n",
       "344  confidence \" . In 2006 , she appeared in a mus...   \n",
       "\n",
       "                                             statement  tag_id  \n",
       "340  . Her father , who was a musician in Sri Lanka...     340  \n",
       "341  age of fourteen . After receiving her early ed...     341  \n",
       "342  , she had aspired to become an actress at a yo...     342  \n",
       "343  was crowned the winner of the Miss Universe Sr...     343  \n",
       "344  , confidence \" . In 2006 , she appeared in a m...     344  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True, lower=True)\n",
    "#LABEL = data.Field(sequential=True, use_vocab=True)\n",
    "#SENTIMENT = data.Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafields = [('tag', TEXT),\n",
    "              ('statement', TEXT),\n",
    "              ('tag_id', None)]\n",
    "\n",
    "train, test = data.TabularDataset.splits(\n",
    "    path=data_path,\n",
    "    train='train.csv', validation='valid.csv',\n",
    "    format='csv',\n",
    "    skip_header=True,\n",
    "    fields=datafields)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_file_imdb = settings.imdb_file\n",
    "train_imdb, valid_imdb = data_import.import_imbd(train_file_imdb, to=10000, test_size=settings.test_size)\n",
    "data_import.create_split_files('./imdb', train_imdb, valid_imdb)\n",
    "\n",
    "datafields = [('tag', None),\n",
    "              ('statement', TEXT),\n",
    "              ('tag_id', SENTIMENT)]\n",
    "\n",
    "train_imdb, test_imdb = data.TabularDataset.splits(\n",
    "    path='./imdb/data',\n",
    "    train='train.csv', validation='valid.csv',\n",
    "    format='csv',\n",
    "    skip_header=True,\n",
    "    fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.build_vocab(train, test, train_imdb, test_imdb, vectors='glove.6B.'+str(settings.emb_dim)+'d')\n",
    "#TEXT.build_vocab(train, test, vectors='glove.6B.'+str(settings.emb_dim)+'d')\n",
    "TEXT.build_vocab(train, test)\n",
    "#LABEL.build_vocab(train, test, vectors='glove.6B.'+str(settings.emb_dim)+'d')\n",
    "#SENTIMENT.build_vocab(train_imdb, test_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_classes = len(LABEL.vocab)\n",
    "#print('Number of classes:', n_classes)\n",
    "#n_sent = len(dict(SENTIMENT.vocab.freqs).keys())\n",
    "#print('Number of sentiments:', n_sent)\n",
    "#print((TEXT.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(trn): 340\n",
      "len(test): 60\n",
      "\n",
      "[('the', 3540), (',', 2518), ('.', 1905), ('<unk>', 1550), ('of', 1349), ('and', 1296), ('in', 1158), ('to', 1033), ('a', 945), ('=', 816), ('was', 692), ('\"', 507), ('@-@', 500), ('for', 473), ('with', 437), (\"'s\", 412), (')', 313), ('(', 312), ('by', 309), ('as', 307)]\n",
      "\n",
      "['<unk>', '<pad>', 'the', ',', '.', 'of', 'and', 'in', 'to', 'a']\n"
     ]
    }
   ],
   "source": [
    "print('len(trn):', len(train))\n",
    "print('len(test):', len(test))\n",
    "print()\n",
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "print()\n",
    "print(TEXT.vocab.itos[:10])\n",
    "#print(vars(train[0]))\n",
    "#print()\n",
    "#print(LABEL.vocab.freqs.most_common(20))\n",
    "#print(LABEL.vocab.itos[:10])\n",
    "#print(LABEL.vocab.stoi)\n",
    "#print(SENTIMENT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4307\n"
     ]
    }
   ],
   "source": [
    "#print(TEXT.vocab.vectors.shape)\n",
    "vocab_size = len(TEXT.vocab)\n",
    "print('Vocab size:',vocab_size)\n",
    "#TEXT.vocab.vectors[TEXT.vocab.stoi['the']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(trn): 340\n",
      "len(vld): 60\n",
      "len(test): 60\n"
     ]
    }
   ],
   "source": [
    "#trn, vld = train.split(0.7)\n",
    "trn = train\n",
    "vld = test\n",
    "print('len(trn):', len(trn))\n",
    "print('len(vld):', len(vld))\n",
    "print('len(test):', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits(\n",
    "    datasets=(trn, vld),\n",
    "    batch_sizes=(settings.batch_size, settings.batch_size),\n",
    "    sort_key=lambda x: len(x.statement),\n",
    "    sort_within_batch=False,\n",
    "    repeat=False,\n",
    "    shuffle=False,\n",
    "    sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, dl, x_field, y_fields):\n",
    "        self.dl, self.x_field, self.y_fields = dl, x_field, y_fields\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x_field)\n",
    "            y = getattr(batch, self.y_fields)\n",
    "            #y = torch.cat([getattr(batch, feat).unsqueeze(1) \n",
    "            #               for feat in self.y_fields], dim=1).float()\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "            yield (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchGenerator(train_iter, 'statement', 'tag')\n",
    "valid_dl = BatchGenerator(val_iter, 'statement', 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleLSTM(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim, n_layers=1, pretrained_vec=torch.zeros(0),\n",
    "                 change_emb=True, dropout=0):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        \n",
    "        self.embedding.weight.requires_grad = change_emb\n",
    "        \n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers=n_layers,\n",
    "                            bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(2*hidden_dim, len(TEXT.vocab))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.init_weights(pretrained_vec)\n",
    "        \n",
    "    def init_weights(self, pretrained_vec, initrange=0.1):\n",
    "        \n",
    "        if len(pretrained_vec) > 0:\n",
    "            print('Loaded pretrained vectors.')\n",
    "            self.embedding.weight.data.copy_(pretrained_vec)\n",
    "        else:\n",
    "            print('Not loaded pretrained vectors, uniform init in [-{}, {}].'.format(initrange, initrange))\n",
    "            self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "            \n",
    "        self.fc.bias.data.zero_()\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        \n",
    "        #pdb.set_trace()\n",
    "        # seq dims: [seq len, batch size]\n",
    "        \n",
    "        emb = self.embedding(seq)\n",
    "        # emb dims: [seq len, batch size, emb dim]\n",
    "        \n",
    "        out, (hid, cel) = self.lstm(emb)\n",
    "        \n",
    "        # out dims: [seq len, batch size, hidden_dim]\n",
    "        # hid dims: [2*n_layers, batch size, hidden_dim]\n",
    "        # cel dims: [2*n_layers, batch size, hidden_dim]\n",
    "        # out[-1,:,:hd] -> [batch size, hidden_dim]  (last time step hidden vector)\n",
    "        # out[0,:,hd:] <- [batch size, hidden_dim]  (first time step hidden vector)\n",
    "        # contatenation of last time period, whole batch, forward (first) chunck of hidden units\n",
    "        #   and the first time period, whole batch, backward (last) chunck of hidden units\n",
    "        #   (pytorch concatenates hidden units across dim #2 for bidirectional LSTM)\n",
    "        #conc = torch.cat((out[-1,:,:self.hidden_dim], out[0,:,self.hidden_dim:]), dim=1)\n",
    "        #conc = self.dropout(conc)\n",
    "        \n",
    "        output = self.dropout(out)\n",
    "        \n",
    "        output = self.fc(output)\n",
    "        \n",
    "        # sm dims: [batch size, n_classes]\n",
    "        #sm = F.log_softmax(output, dim=-1)\n",
    "        #return sm\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not loaded pretrained vectors, uniform init in [-0.1, 0.1].\n"
     ]
    }
   ],
   "source": [
    "model = simpleLSTM(emb_dim=settings.emb_dim,\n",
    "                   hidden_dim=settings.hidden_dim,\n",
    "                   n_layers=settings.num_layers,\n",
    "                   #pretrained_vec=TEXT.vocab.vectors,\n",
    "                   change_emb=True,\n",
    "                   dropout=settings.dropout\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x, y = next(iter(train_dl))\n",
    "preds = model(x)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(preds.shape)\n",
    "print(x)\n",
    "print(y)\n",
    "print(preds.view(-1, preds.size(2)).shape)\n",
    "print(y.view(-1).shape)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss = loss_func(preds.view(-1, preds.size(2)), y.view(-1).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleLSTM(\n",
      "  (embedding): Embedding(4307, 300)\n",
      "  (lstm): LSTM(300, 1150, num_layers=3, dropout=0.4, bidirectional=True)\n",
      "  (fc): Linear(in_features=2300, out_features=4307, bias=True)\n",
      "  (dropout): Dropout(p=0.4)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = torch.load('model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclass = []\n",
    "missclass_next = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def run_epochs(model, train_dl, valid_dl, epochs=settings.epochs,\n",
    "               losses=[], missclass=[]):\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    #opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    #loss_func = nn.NLLLoss()\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.8)\n",
    "    \n",
    "    try: # Allow for user interrupt\n",
    " \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            scheduler.step()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            model.train() # turn on training mode\n",
    "\n",
    "            num_vals = 0\n",
    "            num_correct = 0\n",
    "            miss_next_wd = 0\n",
    "            next_wd_tot = 0\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            for x, y in tqdm(train_dl, desc='Train {}/{}'.format(epoch, epochs)):\n",
    "                opt.zero_grad()\n",
    "\n",
    "                preds = model(x)\n",
    "                loss = loss_func(preds.view(-1, preds.size(2)), y.view(-1).long())\n",
    "\n",
    "                loss.backward()\n",
    "                #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "                opt.step()\n",
    "\n",
    "                running_loss += loss.item() * x.size(0)\n",
    "\n",
    "                _, y_preds = torch.max(preds, dim=2)\n",
    "                num_correct += torch.sum(y == y_preds).item()\n",
    "                num_vals += y.size(0)*y.size(1)\n",
    "                \n",
    "                miss_next_wd += ml_utils.calc_miss_next_wds(y, y_preds)\n",
    "                next_wd_tot += y.size(1)\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            missclass_tr = 1 - num_correct / num_vals\n",
    "            miss_next_wd_rate_tr = miss_next_wd / next_wd_tot\n",
    "\n",
    "            epoch_loss = running_loss / len(trn)\n",
    "\n",
    "            num_vals = 0\n",
    "            num_correct = 0\n",
    "            miss_next_wd = 0\n",
    "            next_wd_tot = 0\n",
    "\n",
    "            # calculate the validation loss for this epoch\n",
    "            val_loss = 0.0\n",
    "            model.eval() # turn on evaluation mode\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for x, y in tqdm(valid_dl, desc='Valid {}/{}'.format(epoch, epochs)):\n",
    "                    preds = model(x)\n",
    "                    loss = loss_func(preds.view(-1, preds.size(2)), y.view(-1).long())\n",
    "\n",
    "                    val_loss += loss.item() * x.size(0)\n",
    "\n",
    "                    _, y_preds = torch.max(preds, dim=2)\n",
    "                    num_correct += torch.sum(y == y_preds).item()\n",
    "                    num_vals += y.size(0)*y.size(1)\n",
    "                    \n",
    "                    miss_next_wd += ml_utils.calc_miss_next_wds(y, y_preds)\n",
    "                    next_wd_tot += y.size(1)\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            missclass_te = 1 - num_correct / num_vals\n",
    "            val_loss /= len(vld)\n",
    "            \n",
    "            miss_next_wd_rate_val = miss_next_wd / next_wd_tot\n",
    "            \n",
    "            missclass_next.append((miss_next_wd_rate_tr, miss_next_wd_rate_val))\n",
    "            missclass.append((missclass_tr, missclass_te))\n",
    "            losses.append((epoch_loss, val_loss))\n",
    "\n",
    "            print('Epoch: {}/{}, Loss: [{:.4f}, {:.4f}], Ppl: [{:6.2f}, {:6.2f}], Miss: [{:.2%}, {:.2%}], [{:.2%}, {:.2%}]'\\\n",
    "                  .format(epoch, epochs, epoch_loss, val_loss, \n",
    "                          math.exp(epoch_loss), math.exp(val_loss), \n",
    "                          missclass_tr, missclass_te,\n",
    "                          miss_next_wd_rate_tr, miss_next_wd_rate_val))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            print('Saving weights file...', end=' ', flush=True)\n",
    "            torch.save(model, 'model_weights.pt')\n",
    "            print('Done.', flush=True)\n",
    "            #to load: model = torch.load('model_weights.pt')\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print('Stopping with latest weights.')\n",
    "        \n",
    "    return model, opt, losses, missclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1/10: 100%|██████████| 5/5 [03:11<00:00, 38.26s/it]\n",
      "Valid 1/10: 100%|██████████| 1/1 [00:05<00:00,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Loss: [18.1002, 9.6992], Ppl: [72578770.21, 16304.52], Miss: [96.66%, 99.84%], [95.59%, 100.00%]\n",
      "Saving weights file... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/anaconda3/envs/ONE/lib/python3.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type simpleLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2/10:  40%|████      | 2/5 [01:21<02:02, 40.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping with latest weights.\n"
     ]
    }
   ],
   "source": [
    "model, opt, losses, missclass = run_epochs(model, train_dl, valid_dl, epochs=settings.epochs,\n",
    "                                           losses=losses, missclass=missclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(valid_dl))\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "preds = model(x)\n",
    "_, y_preds = torch.max(preds, dim=2)\n",
    "ml_utils.calc_miss_next_wds(y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([61, 60])\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 83, 358,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   7,   5,   7,\n",
       "          6,   6,   2,   2,   7,   2,   2,   2,   2,   2,   2,   7,   2,   2,\n",
       "          2,   2,   2,   7,   2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1d017898>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(missclass)\n",
    "plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(missclass_next)\n",
    "plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Replace fc with sentiment layer\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, n_sent)\n",
    "if cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_imdb_iter, val_imdb_iter = data.BucketIterator.splits(\n",
    "    datasets=(train_imdb, test_imdb),\n",
    "    batch_sizes=(settings.batch_size, settings.batch_size),\n",
    "    sort_key=lambda x: len(x.statement),\n",
    "    sort_within_batch=False,\n",
    "    repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_imdb_dl = BatchGenerator(train_imdb_iter, 'statement', 'tag_id')\n",
    "valid_imdb_dl = BatchGenerator(val_imdb_iter, 'statement', 'tag_id')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model, opt, losses, missclass = run_epochs(model, train_imdb_dl, valid_imdb_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
