{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create python file:\n",
    "# jupyter nbconvert --to=python lang_model_new.ipynb\n",
    "\n",
    "import utils.data_import as data_import\n",
    "import utils.wiki_data as wiki_data\n",
    "import utils.ml_utils as ml_utils\n",
    "import model.neural as neural\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data, vocab\n",
    "\n",
    "import os, sys\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "#from tqdm import tnrange, tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import importlib\n",
    "\n",
    "import settings\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in notebook: True\n"
     ]
    }
   ],
   "source": [
    "in_notebook = ml_utils.in_ipynb()\n",
    "print('Running in notebook:', in_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available!\n",
      "Device: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    print('Cuda is available!')\n",
    "    print('Device:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print('No cuda.')\n",
    "\n",
    "if in_notebook:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated train: 121,423,332 tokens (1,801,349 lines)\n",
      "Generated valid: 258,407 tokens (3,759 lines)\n",
      "Generated test:  288,663 tokens (4,357 lines)\n",
      "Generated vocab: 226,993\n",
      "Generated oov:   0.4%\n"
     ]
    }
   ],
   "source": [
    "corpus = wiki_data.WikiCorpus(file_path=settings.wikitext_path, lines=settings.lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: keeping special token <pad>\n",
      "Processing 166,993 tokens for removal.\n",
      "Updating corpus vocabulary... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226993/226993 [06:49<00:00, 553.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166,993 removed.\n",
      "Replacing tokens in train... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102,296,412 substitutions.\n",
      "Replacing tokens in valid... 215,302 substitutions.\n",
      "Replacing tokens in test... 241,947 substitutions.\n",
      "Final vocabulary size: 60,000 tokens\n",
      "Exporting vocab to vocab.p... Done.\n"
     ]
    }
   ],
   "source": [
    "if settings.maxvocabsize < len(corpus.vocab):\n",
    "    remove = corpus.vocab.least_frequent(len(corpus.vocab) - settings.maxvocabsize + 1)\n",
    "    remove = [tok[0] for tok in remove]\n",
    "    corpus.remove_token_list(remove)\n",
    "    \n",
    "corpus.vocab.export_vocab('vocab.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batchifying train... Done.  torch.Size([1517791, 80])\n",
      "Batchifying valid... Done.  torch.Size([3230, 80])\n",
      "Batchifying test...  Done.  torch.Size([3608, 80])\n"
     ]
    }
   ],
   "source": [
    "corpus.batchify(batch_size=settings.batch_size, seq_length=settings.window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287 270 1806 299 70 16 380 408 2718 12 16 3 19644 1429 3573 1759 1576 44 16 7026 29 30 29 10064 15 16 2726 80 16 3 15102 3 48568 139 3 51670 129 2995 216 3984 1303 114 16 35175 92 16 553 659 15 16 33 14 1 3 22 26 3000 12 3 51670 708 1375 29 12 29 3278 3940 37 2381 2807 None\n",
      "up only 19 points during the entire regular season , the <upcase> knights lost 32 – 26 in the quarter @ - @ finals of the playoffs against the <upcase> centennial <upcase> centaurs after <upcase> mccarty was stopped one yard away from the endzone on the last play of the game . <eol> <upcase> as a senior , <upcase> mccarty recorded 2 @ , @ 400 yards and scored 33 None\n",
      "tensor([   44,    16,     3,  1064,    12,   216,    15,    16,     3,     2,\n",
      "           29,    30,    29,   330,     3,  8166,  6917,    16,     3,    11,\n",
      "            2,     3,     2,     3, 45850,    12,   312,   129,  9864,    15,\n",
      "          303,    26,  6276,  3640,    12,    37,  1259,    47,  3642,    14,\n",
      "            3,    35,  1701,     3,  2846,    12,     3, 58911,   510,  1153,\n",
      "           21,     3,     2,    22,   507,   420,    15,    16,  2450,    12,\n",
      "           22,  1351,    22,     3,     7,    14,  1375,     3,  3904,    14])\n",
      "count    48.000000\n",
      "mean     67.270833\n",
      "std       8.383722\n",
      "min      31.000000\n",
      "25%      65.000000\n",
      "50%      68.500000\n",
      "75%      72.000000\n",
      "max      86.000000\n",
      "Name: len, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if in_notebook:\n",
    "    print(corpus.valid.show_itoklist(29629,29629+70))\n",
    "    print(corpus.valid.show_stoklist(corpus.vocab, 29629,29629+70))\n",
    "    print(corpus.valid.batch_matrix[:70,1])\n",
    "    df = corpus.valid.batch_stats()\n",
    "    df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = wiki_data.WikiTextDataset(corpus.train)\n",
    "valid_dl = wiki_data.WikiTextDataset(corpus.valid)\n",
    "test_dl = wiki_data.WikiTextDataset(corpus.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neural.lang_model_LSTM(vocab_dim=len(corpus.vocab),\n",
    "                               emb_dim=settings.emb_dim,\n",
    "                               hidden_dim=settings.hidden_dim,\n",
    "                               n_layers=settings.num_layers,\n",
    "                               dropout=settings.dropout\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    model = model.cuda()\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang_model_LSTM(\n",
      "  (embedding): Embedding(60000, 400)\n",
      "  (lstm): LSTM(400, 1150, num_layers=2, dropout=0.4, bidirectional=True)\n",
      "  (fc): Linear(in_features=2300, out_features=60000, bias=True)\n",
      "  (dropout): Dropout(p=0.4)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclass = []\n",
    "missclass_next = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epochs(model, train_dl, valid_dl, epochs=settings.epochs,\n",
    "               losses=[], missclass=[]):\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    #opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.8)\n",
    "    \n",
    "    best_missclass_te = 1e10\n",
    "    \n",
    "    try: # Allow for user interrupt\n",
    " \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            scheduler.step()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            model.train() # turn on training mode\n",
    "\n",
    "            num_vals = 0\n",
    "            num_correct = 0\n",
    "            miss_next_wd = 0\n",
    "            next_wd_tot = 0\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            for x, y in tqdm(train_dl, desc='Train {}/{}'.format(epoch, epochs)):\n",
    "                opt.zero_grad()\n",
    "                \n",
    "                if cuda:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "\n",
    "                preds = model(x)\n",
    "                loss = loss_func(preds.view(-1, preds.size(2)), y.view(-1).long())\n",
    "\n",
    "                loss.backward()\n",
    "                #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "                opt.step()\n",
    "\n",
    "                running_loss += loss.item() * x.size(0) / x.size(1)\n",
    "\n",
    "                _, y_preds = torch.max(preds, dim=2)\n",
    "                num_correct += torch.sum(y == y_preds).item()\n",
    "                num_vals += y.size(0)*y.size(1)\n",
    "                \n",
    "                miss_next_wd += ml_utils.calc_miss_next_wds(y, y_preds)\n",
    "                next_wd_tot += y.size(1)\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            missclass_tr = 1 - num_correct / num_vals\n",
    "            miss_next_wd_rate_tr = miss_next_wd / next_wd_tot\n",
    "\n",
    "            epoch_loss = running_loss / len(train_dl)\n",
    "\n",
    "            num_vals = 0\n",
    "            num_correct = 0\n",
    "            miss_next_wd = 0\n",
    "            next_wd_tot = 0\n",
    "\n",
    "            # calculate the validation loss for this epoch\n",
    "            val_loss = 0.0\n",
    "            model.eval() # turn on evaluation mode\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for x, y in tqdm(valid_dl, desc='Valid {}/{}'.format(epoch, epochs)):\n",
    "                    if cuda:\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()   \n",
    "                        \n",
    "                    preds = model(x)\n",
    "                    loss = loss_func(preds.view(-1, preds.size(2)), y.view(-1).long())\n",
    "\n",
    "                    val_loss += loss.item() * x.size(0) / x.size(1)\n",
    "\n",
    "                    _, y_preds = torch.max(preds, dim=2)\n",
    "                    num_correct += torch.sum(y == y_preds).item()\n",
    "                    num_vals += y.size(0)*y.size(1)\n",
    "                    \n",
    "                    miss_next_wd += ml_utils.calc_miss_next_wds(y, y_preds)\n",
    "                    next_wd_tot += y.size(1)\n",
    "\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            missclass_te = 1 - num_correct / num_vals\n",
    "            val_loss /= len(valid_dl)\n",
    "            \n",
    "            miss_next_wd_rate_val = miss_next_wd / next_wd_tot\n",
    "            \n",
    "            missclass_next.append((miss_next_wd_rate_tr, miss_next_wd_rate_val))\n",
    "            missclass.append((missclass_tr, missclass_te))\n",
    "            losses.append((epoch_loss, val_loss))\n",
    "\n",
    "            print('Epoch: {}/{}, Loss: [{:.4f}, {:.4f}], Ppl: [{:6.2f}, {:6.2f}], Miss: [{:.2%}, {:.2%}], [{:.2%}, {:.2%}]'\\\n",
    "                  .format(epoch, epochs, epoch_loss, val_loss, \n",
    "                          math.exp(epoch_loss), math.exp(val_loss), \n",
    "                          missclass_tr, missclass_te,\n",
    "                          miss_next_wd_rate_tr, miss_next_wd_rate_val))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            if missclass_te < best_missclass_te: \n",
    "                print('Saving weights file...', end=' ', flush=True)\n",
    "                torch.save(model, 'model_weights.pt')\n",
    "                print('Done.', flush=True)\n",
    "                best_missclass_te = missclass_te\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print('Stopping with latest weights.')\n",
    "        \n",
    "    return model, opt, losses, missclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1/100:   8%|▊         | 1806/22406 [20:41<3:55:57,  1.46it/s]"
     ]
    }
   ],
   "source": [
    "model, opt, losses, missclass = run_epochs(model, train_dl, valid_dl, epochs=settings.epochs,\n",
    "                                           losses=losses, missclass=missclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(valid_dl))\n",
    "if cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "preds = model(x)\n",
    "_, y_preds = torch.max(preds, dim=2)\n",
    "ml_utils.calc_miss_next_wds(y, y_preds)\n",
    "loss = loss_func(preds.view(-1, preds.size(2)), y.view(-1).long())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(y[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_preds[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_notebook:\n",
    "    plt.plot(losses)\n",
    "    plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_notebook:\n",
    "    plt.plot(missclass)\n",
    "    plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_notebook:\n",
    "    plt.plot(missclass_next)\n",
    "    plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not in_notebook:\n",
    "    print('losses =', losses)\n",
    "    print('missclass =', missclass)\n",
    "    print('missclass_next =', missclass_next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
